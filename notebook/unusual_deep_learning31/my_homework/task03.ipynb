{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task03 前馈神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 神经元模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 神经元M-P模型：接收n个神经元的输入信号，经过加权求和，结果与阈值$\\theta$比较，经过激活函数得到输出\n",
    "- 模型：$$y=f \\left( \\sum_{i=1}^{n} \\omega_{ij} x_{i} - \\theta \\right)$$\n",
    "- 表达性：可表示多种逻辑运算（取反运算、逻辑与、逻辑或）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 感知器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 单层感知器\n",
    "\n",
    "- 概念：感知器能够通过有监督学习训练，自动确定模型参数，通过设定训练样本和期望输出，调整实际输出和期望输出之差，进行误差修正学习\n",
    "- 模型公式：\n",
    "$$\n",
    "\\begin{aligned} \n",
    "w_i & \\leftarrow w_i + \\alpha(r-y) x \\\\ \n",
    "\\theta & \\leftarrow \\theta - \\alpha(r-y) \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练步骤：\n",
    "  1. 准备$N$个训练样本$x_i$，初始化期望输出$r_i$\n",
    "  2. 初始化训练参数$w_i$和$\\theta$\n",
    "  3. 迭代调整参数，直到误差为0或者小于$\\varepsilon$\n",
    "  4. 逐个加入训练样本，计算实际输出：当实际输出和期望输出相等，参数不变；否则，进行误差修正，调整参数\n",
    "  5. 回到步骤（3）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 多层感知器\n",
    "\n",
    "- 概念：多层结构的感知器递进组成的向前传播的网络，称为前馈网络或正向传播网络\n",
    "- 三层感知器：输入层、中间层、输出层，之间通过权重相连。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 BP算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 BP算法基本过程\n",
    "\n",
    "- 基本思路：通过计算实际输出与期望输出的误差，把误差进行反向传递，通过调整各层的连接权重减小误差，采用梯度下降法调整权重\n",
    "- 主要步骤：\n",
    "  1. 前向传播计算：从输入层经过隐含层向输出层，计算网络输出\n",
    "  2. 误差反向逐层传递：计算实际输出与期望输出之差，并反向传递\n",
    "  3. 反复上述两步，对网络进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 激活函数\n",
    "\n",
    "- 阶跃函数：只输出0或1，函数不连续，不可导\n",
    "$$\n",
    "f(x) = \\begin{cases}\n",
    "0, \\quad x < 0 \\\\ \n",
    "1, \\quad x > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "- sigmoid函数：\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "- ReLu函数（修正线性单元）：\n",
    "$$\n",
    "\\text{ReLu}(x) = \n",
    "\\begin{cases} \n",
    "x, \\quad x > 0 \\\\\n",
    "0, \\quad \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "- tanh函数：\n",
    "$$\n",
    "\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 BP算法示例\n",
    "\n",
    "1. 假设某个多层感知器：包含一个中间层和一个输出单元$y$，其中$w_{1ij}$ 表示输入层与中间层之间的连接权重，$w_{2j1}$ 表示中间层与输出层之间的连接权重， $i$ 表示输入层单元，$j$ 表示中间层单元。\n",
    "2. 调整中间层与输出层之间的连接权重：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial E}{\\partial w_{2 j 1}} \n",
    "&= \\frac{\\partial E}{\\partial y} \\frac{\\partial y}{\\partial u_{21}} \\frac{\\partial u_{21}}{\\partial w_{2 j 1}} \\\\ \n",
    "&= -(r-y) y(1-y) z_{j}\n",
    "\\end{aligned}\n",
    "$$\n",
    "3. 调整中间层到输出层之间的连接权重：\n",
    "$$\n",
    "\\Delta w_{2 j 1}=\\alpha(r-y) y(1-y) z_{j} \\\\\n",
    "\\begin{aligned} \n",
    "\\frac{\\partial E}{\\partial w_{1 i j}} \n",
    "&= \\frac{\\partial E}{\\partial y} \\frac{\\partial y}{\\partial u_{21}} \\frac{\\partial u_{21}}{\\partial w_{1 i j}} \\\\ \n",
    "&= -(r-y) y(1-y) \\frac{\\partial u_{21}}{\\partial w_{1 i j}} \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 存在的优化问题\n",
    "\n",
    "- 难点：\n",
    "  1. 参数过多，影响训练\n",
    "  2. 非凸优化问题：即存在局部最优而非全局最优解，影响迭代\n",
    "  3. 梯度消失问题，下层参数较难调整\n",
    "  4. 参数解释性不强\n",
    "\n",
    "\n",
    "- 需求：\n",
    "  1. 计算所需的资源多\n",
    "  2. 需要更多的样本数据\n",
    "  3. 需要更好的算法效率，即模型收敛快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;本次任务，主要介绍了前馈神经网络，神经元模型也称为M-P模型，后提出感知器，采用有监督学习的方式进行模型训练，能够自动确定参数，主要学习方法是误差修正；之后BP算法，也称为误差反向传播算法，通过计算实际输出与期望输出的误差，把误差进行反向传递，采用梯度下降法调整各层的连接权重减小误差。该算法主要存在一些难点：参数过多，无法解决非凸优化问题，存在梯度消失问题，参数的解释性不强。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
