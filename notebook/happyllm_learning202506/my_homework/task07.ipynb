{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdff8f36",
   "metadata": {},
   "source": [
    "# Task07 大模型应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c23369",
   "metadata": {},
   "source": [
    "## 1 LLM 的评测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfc242",
   "metadata": {},
   "source": [
    "- LLM 的评测数据集：通用评测集（MMLU）、工具使用评测集（BFCL V2、Nexus）、数学评测集（GSM8K、MATH）、推理评测集（ARC Challenge、GPQA、HellaSwag）、长文本理解评测集（InfiniteBench/En.MC、NIH/Multi-needle）、多语言评测集（MGSM）\n",
    "- 主流评测榜单：Open LLM Leaderboard、Lmsys Chatbot Arena Leaderboard、OpenCompass。\n",
    "- 垂类评测榜单：金融榜（基于CFBenchmark评测集）、安全榜（基于Flames评测集）、通识榜（基于BotChat评测集）、法律榜（基于LawBench评测集）、医疗榜（基于MedBench评测集）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c690c",
   "metadata": {},
   "source": [
    "## 2 RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc119c30",
   "metadata": {},
   "source": [
    "### 2.1 RAG原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179bf90",
   "metadata": {},
   "source": [
    "将“检索”与“生成”结合，当用户提出查询时，系统首先通过检索模块找到与问题相关的文本片段，然后将这些片段作为附加信息传递给语言模型，模型据此生成更为精准和可靠的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0420e9",
   "metadata": {},
   "source": [
    "### 2.2 搭建一个 RAG 框架"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d23db5",
   "metadata": {},
   "source": [
    "- RAG基本结构：向量化模块、文档加载和切分模块、数据库、检索模块、大模型模块。\n",
    "- RAG主要流程：索引、检索、生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637bf9f",
   "metadata": {},
   "source": [
    "1. 加载python依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a5e5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "import PyPDF2\n",
    "import markdown\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706c277",
   "metadata": {},
   "source": [
    "2. 加载环境变量，用于加载API_KEY。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1696fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc5a56",
   "metadata": {},
   "source": [
    "3. 实现RAG向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a41a158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEmbeddings:\n",
    "    \"\"\"\n",
    "    向量化基类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str, is_api: bool) -> None:\n",
    "        self.path = path\n",
    "        self.is_api = is_api\n",
    "\n",
    "    def get_embedding(self, text: str, model: str=None) -> List[float]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def cosine_similarity(cls, vector1: List[float], vector2: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        计算两个向量的余弦相似度\n",
    "        :param vector1: 向量1\n",
    "        :param vector2: 向量2\n",
    "        :return: 两个向量的相似度\n",
    "        \"\"\"\n",
    "        dot_product = np.dot(vector1, vector2)\n",
    "        magnitude = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
    "        if not magnitude:\n",
    "            return 0\n",
    "        return dot_product / magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea78b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiliconFlowEmbedding(BaseEmbeddings):\n",
    "    \"\"\"\n",
    "    基于硅基流动的向量化类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str = '', is_api: bool = True) -> None:\n",
    "        super().__init__(path, is_api)\n",
    "        if self.is_api:\n",
    "            from openai import OpenAI\n",
    "            API_KEY = os.getenv(\"SiliconFlow_API_KEY\")\n",
    "            BASE_URL = os.getenv(\"SiliconFlow_BASE_URL\")\n",
    "            self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "\n",
    "    def get_embedding(self, text: str, model: str = \"BAAI/bge-m3\") -> List[float]:\n",
    "        if self.is_api:\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "            return self.client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34604c60",
   "metadata": {},
   "source": [
    "4. 实现文档加载和切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb77f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadFiles:\n",
    "    \"\"\"\n",
    "    class to read files\n",
    "    \"\"\"\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self._path = path\n",
    "        self.file_list = self.get_files()\n",
    "\n",
    "    def get_files(self):\n",
    "        # args：dir_path，目标文件夹路径\n",
    "        file_list = []\n",
    "        for filepath, dirnames, filenames in os.walk(self._path):\n",
    "            # os.walk 函数将递归遍历指定文件夹\n",
    "            for filename in filenames:\n",
    "                # 通过后缀名判断文件类型是否满足要求\n",
    "                if filename.endswith(\".md\"):\n",
    "                    # 如果满足要求，将其绝对路径加入到结果列表\n",
    "                    file_list.append(os.path.join(filepath, filename))\n",
    "                elif filename.endswith(\".txt\"):\n",
    "                    file_list.append(os.path.join(filepath, filename))\n",
    "                elif filename.endswith(\".pdf\"):\n",
    "                    file_list.append(os.path.join(filepath, filename))\n",
    "        return file_list\n",
    "\n",
    "    def get_content(self, max_token_len: int = 600, cover_content: int = 150):\n",
    "        docs = []\n",
    "        # 读取文件内容\n",
    "        for file in self.file_list:\n",
    "            content = self.read_file_content(file)\n",
    "            chunk_content = self.get_chunk(\n",
    "                content, max_token_len=max_token_len, cover_content=cover_content)\n",
    "            docs.extend(chunk_content)\n",
    "        return docs\n",
    "\n",
    "    @classmethod\n",
    "    def read_file_content(cls, file_path: str):\n",
    "        \"\"\"\n",
    "        根据文件扩展名选择读取方法\n",
    "        \"\"\"\n",
    "        if file_path.endswith('.pdf'):\n",
    "            return cls.read_pdf(file_path)\n",
    "        elif file_path.endswith('.md'):\n",
    "            return cls.read_markdown(file_path)\n",
    "        elif file_path.endswith('.txt'):\n",
    "            return cls.read_text(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_chunk(cls, text: str, max_token_len: int = 600, cover_content: int = 150):\n",
    "        chunk_text = []\n",
    "\n",
    "        curr_len = 0\n",
    "        curr_chunk = ''\n",
    "\n",
    "        token_len = max_token_len - cover_content\n",
    "        lines = text.splitlines()  # 假设以换行符分割文本为行\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.replace(' ', '')\n",
    "            line_len = len(cls.enc.encode(line))\n",
    "            if line_len > max_token_len:\n",
    "                # 如果单行长度就超过限制，则将其分割成多个块\n",
    "                num_chunks = (line_len + token_len - 1) // token_len\n",
    "                for i in range(num_chunks):\n",
    "                    start = i * token_len\n",
    "                    end = start + token_len\n",
    "                    # 避免跨单词分割\n",
    "                    while not line[start:end].rstrip().isspace():\n",
    "                        start += 1\n",
    "                        end += 1\n",
    "                        if start >= line_len:\n",
    "                            break\n",
    "                    curr_chunk = curr_chunk[-cover_content:] + line[start:end]\n",
    "                    chunk_text.append(curr_chunk)\n",
    "                # 处理最后一个块\n",
    "                start = (num_chunks - 1) * token_len\n",
    "                curr_chunk = curr_chunk[-cover_content:] + line[start:end]\n",
    "                chunk_text.append(curr_chunk)\n",
    "\n",
    "            if curr_len + line_len <= token_len:\n",
    "                curr_chunk += line\n",
    "                curr_chunk += '\\n'\n",
    "                curr_len += line_len\n",
    "                curr_len += 1\n",
    "            else:\n",
    "                chunk_text.append(curr_chunk)\n",
    "                curr_chunk = curr_chunk[-cover_content:] + line\n",
    "                curr_len = line_len + cover_content\n",
    "\n",
    "        if curr_chunk:\n",
    "            chunk_text.append(curr_chunk)\n",
    "\n",
    "        return chunk_text\n",
    "\n",
    "    @classmethod\n",
    "    def read_pdf(cls, file_path: str):\n",
    "        # 读取PDF文件\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                text += reader.pages[page_num].extract_text()\n",
    "            return text\n",
    "\n",
    "    @classmethod\n",
    "    def read_markdown(cls, file_path: str):\n",
    "        # 读取Markdown文件\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            md_text = file.read()\n",
    "            html_text = markdown.markdown(md_text)\n",
    "            # 使用BeautifulSoup从HTML中提取纯文本\n",
    "            soup = BeautifulSoup(html_text, 'html.parser')\n",
    "            plain_text = soup.get_text()\n",
    "            # 使用正则表达式移除网址链接\n",
    "            text = re.sub(r'http\\S+', '', plain_text)\n",
    "            return text\n",
    "\n",
    "    @classmethod\n",
    "    def read_text(cls, file_path: str):\n",
    "        # 读取文本文件\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b21999",
   "metadata": {},
   "source": [
    "5. 实现数据库与向量检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7710f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, document=None) -> None:\n",
    "        self.vectors = None\n",
    "        if document is None:\n",
    "            document = ['']\n",
    "        self.document = document\n",
    "\n",
    "    def get_vector(self, EmbeddingModel: BaseEmbeddings) -> List[List[float]]:\n",
    "        self.vectors = []\n",
    "        for doc in tqdm(self.document, desc=\"Calculating embeddings\"):\n",
    "            self.vectors.append(EmbeddingModel.get_embedding(doc))\n",
    "        return self.vectors\n",
    "\n",
    "    def persist(self, path: str = '../../storage'):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        with open(f\"{path}/doecment.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.document, f, ensure_ascii=False)\n",
    "        if self.vectors:\n",
    "            with open(f\"{path}/vectors.json\", 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.vectors, f)\n",
    "\n",
    "    def load_vector(self, path: str = 'storage'):\n",
    "        with open(f\"{path}/vectors.json\", 'r', encoding='utf-8') as f:\n",
    "            self.vectors = json.load(f)\n",
    "        with open(f\"{path}/doecment.json\", 'r', encoding='utf-8') as f:\n",
    "            self.document = json.load(f)\n",
    "\n",
    "    def get_similarity(self, vector1: List[float], vector2: List[float]) -> float:\n",
    "        return BaseEmbeddings.cosine_similarity(vector1, vector2)\n",
    "\n",
    "    def query(self, query: str, EmbeddingModel: BaseEmbeddings, k: int = 1) -> List[str]:\n",
    "        query_vector = EmbeddingModel.get_embedding(query)\n",
    "        result = np.array([self.get_similarity(query_vector, vector)\n",
    "                           for vector in self.vectors])\n",
    "        return np.array(self.document)[result.argsort()[-k:][::-1]].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248dc989",
   "metadata": {},
   "source": [
    "6. 实现大模型模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41ff0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self, path: str = '') -> None:\n",
    "        self.path = path\n",
    "\n",
    "    def chat(self, prompt: str, history: List[dict], content: str) -> str:\n",
    "        pass\n",
    "\n",
    "    def load_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5b5485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiliconFlowChat(BaseModel):\n",
    "    def __init__(self, path: str = '', model: str = \"Qwen/Qwen3-8B\") -> None:\n",
    "        super().__init__(path)\n",
    "        self.model = model\n",
    "\n",
    "    def chat(self, prompt: str, history: List[dict], content: str) -> str:\n",
    "        from openai import OpenAI\n",
    "        API_KEY = os.getenv(\"SiliconFlow_API_KEY\")\n",
    "        BASE_URL = os.getenv(\"SiliconFlow_BASE_URL\")\n",
    "        client = OpenAI(api_key=API_KEY, base_url=BASE_URL, max_retries=3)\n",
    "        history.append({'role': 'user',\n",
    "                        'content': PROMPT_TEMPLATE['RAG_PROMPT_TEMPLATE'].format(question=prompt, context=content)})\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=history,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f57920",
   "metadata": {},
   "source": [
    "7. 用一个字典来保存所有的prompt，方便维护"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "324eb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = dict(\n",
    "    RAG_PROMPT_TEMPLATE=\"\"\"使用以上下文来回答用户的问题。如果你不知道答案，就说你不知道。总是使用中文回答。\n",
    "        问题: {question}\n",
    "        可参考的上下文：\n",
    "        ···\n",
    "        {context}\n",
    "        ···\n",
    "        如果给定的上下文无法让你做出回答，请回答数据库中没有这个内容，你不知道。\n",
    "        有用的回答:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb71ad",
   "metadata": {},
   "source": [
    "8. 开始基于知识库聊天了，我们上传了一个Git介绍的文档，然后可以针对这个文档来提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f65ed71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git的原理主要基于以下核心概念和机制：\n",
      "\n",
      "1. 三大区域结构：\n",
      "- 工作区：直接编辑文件的物理目录\n",
      "- 暂存区（Index）：临时存储变更的快照区\n",
      "- 版本库：永久存储项目历史的数据库\n",
      "\n",
      "2. 三大状态转换：\n",
      "- 已修改 → git add → 已暂存\n",
      "- 已暂存 → git commit → 已提交\n",
      "- 已提交 → git checkout → 工作区\n",
      "\n",
      "3. 分布式架构：\n",
      "每个开发者本地都有完整的版本库，包含全部历史记录，通过推送(push)/拉取(pull)实现协作。\n",
      "\n",
      "4. 数据存储原理：\n",
      "使用SHA-1哈希算法生成唯一对象ID，以键值对形式存储：\n",
      "- blob对象：存储文件内容\n",
      "- tree对象：记录目录结构\n",
      "- commit对象：包含提交元数据和指向tree的指针\n",
      "\n",
      "5. 版本控制机制：\n",
      "通过有向无环图(DAG)管理提交历史，分支只是指向特定提交的可变指针。\n",
      "\n",
      "这种设计使得Git具有强大的分支管理能力、高效的本地操作和完整的历史追溯功能。\n"
     ]
    }
   ],
   "source": [
    "# 没有保存数据库\n",
    "rf = ReadFiles('../data')\n",
    "docs = rf.get_content(max_token_len=600, cover_content=150)  # 获取data目录下的所有文件内容并分割\n",
    "vector = VectorStore(docs)\n",
    "embedding = SiliconFlowEmbedding()  # 创建EmbeddingModel\n",
    "vector.get_vector(EmbeddingModel=embedding)\n",
    "# 将向量和文档内容保存到storage目录，下次再用可以直接加载本地数据库\n",
    "vector.persist(path='../storage')\n",
    "\n",
    "question = 'git的原理是什么？'\n",
    "\n",
    "rag_content = vector.query(question, embedding, k=1)[0]\n",
    "chat = SiliconFlowChat(model=\"deepseek-ai/DeepSeek-V3\")\n",
    "print(chat.chat(question, [], rag_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d1be3",
   "metadata": {},
   "source": [
    "## 3 Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40575fe2",
   "metadata": {},
   "source": [
    "### 3.1 LLM Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e43013",
   "metadata": {},
   "source": [
    "- LLM Agent简介：大模型Agent是一个以LLM为核心“大脑”，并赋予其自主规划、记忆和使用工具能力的系统。\n",
    "- LLM Agent 的类型：\n",
    "    1. 任务导向型Agent：专注于完成特定领域的、定义明确的任务，使用预设的流程和可调用的特定工具集。\n",
    "    2. 规划与推理型Agent：强调自主分解复杂任务、制定多步计划，采用特定的思维框架。\n",
    "    3. 多Agent系统：由多个具有不同角色或能力的Agent协同工作，共同完成一个更宏大的目标。\n",
    "    4. 探索与学习型Agent： 不仅执行任务，还能在与环境的交互中主动学习新知识、新技能或优化自身策略，可能包含更复杂的记忆和反思机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc1211",
   "metadata": {},
   "source": [
    "### 3.2 搭建一个Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77a51d",
   "metadata": {},
   "source": [
    "1. 加载python依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "888ad3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f703b",
   "metadata": {},
   "source": [
    "2. 初始化客户端和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afb3f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "API_KEY = os.getenv(\"SiliconFlow_API_KEY\")\n",
    "BASE_URL = os.getenv(\"SiliconFlow_BASE_URL\")\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500af77f",
   "metadata": {},
   "source": [
    "3. 定义工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "283d7b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_datetime() -> str:\n",
    "    \"\"\"\n",
    "    获取当前日期和时间。\n",
    "    :return: 当前日期和时间的字符串表示。\n",
    "    \"\"\"\n",
    "    current_datetime = datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return formatted_datetime\n",
    "\n",
    "\n",
    "def add(a: float, b: float):\n",
    "    \"\"\"\n",
    "    计算两个浮点数的和。\n",
    "    :param a: 第一个浮点数。\n",
    "    :param b: 第二个浮点数。\n",
    "    :return: 两个浮点数的和。\n",
    "    \"\"\"\n",
    "    return str(a + b)\n",
    "\n",
    "\n",
    "def mul(a: float, b: float):\n",
    "    \"\"\"\n",
    "    计算两个浮点数的积。\n",
    "    :param a: 第一个浮点数。\n",
    "    :param b: 第二个浮点数。\n",
    "    :return: 两个浮点数的积。\n",
    "    \"\"\"\n",
    "    return str(a * b)\n",
    "\n",
    "\n",
    "def compare(a: float, b: float):\n",
    "    \"\"\"\n",
    "    比较两个浮点数的大小。\n",
    "    :param a: 第一个浮点数。\n",
    "    :param b: 第二个浮点数。\n",
    "    :return: 比较结果的字符串表示。\n",
    "    \"\"\"\n",
    "    if a > b:\n",
    "        return f'{a} is greater than {b}'\n",
    "    elif a < b:\n",
    "        return f'{b} is greater than {a}'\n",
    "    else:\n",
    "        return f'{a} is equal to {b}'\n",
    "\n",
    "\n",
    "def count_letter_in_string(a: str, b: str):\n",
    "    \"\"\"\n",
    "    统计字符串中某个字母的出现次数。\n",
    "    :param a: 要搜索的字符串。\n",
    "    :param b: 要统计的字母。\n",
    "    :return: 字母在字符串中出现的次数。\n",
    "    \"\"\"\n",
    "    string = a.lower()\n",
    "    letter = b.lower()\n",
    "\n",
    "    count = string.count(letter)\n",
    "    return f\"The letter '{letter}' appears {count} times in the string.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be2349",
   "metadata": {},
   "source": [
    "4. 将工具类转换成特定的 JSON Schema 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22aa0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_json(func) -> dict:\n",
    "    # 定义 Python 类型到 JSON 数据类型的映射\n",
    "    type_map = {\n",
    "        str: \"string\",  # 字符串类型映射为 JSON 的 \"string\"\n",
    "        int: \"integer\",  # 整型类型映射为 JSON 的 \"integer\"\n",
    "        float: \"number\",  # 浮点型映射为 JSON 的 \"number\"\n",
    "        bool: \"boolean\",  # 布尔型映射为 JSON 的 \"boolean\"\n",
    "        list: \"array\",  # 列表类型映射为 JSON 的 \"array\"\n",
    "        dict: \"object\",  # 字典类型映射为 JSON 的 \"object\"\n",
    "        type(None): \"null\",  # None 类型映射为 JSON 的 \"null\"\n",
    "    }\n",
    "\n",
    "    # 获取函数的签名信息\n",
    "    try:\n",
    "        signature = inspect.signature(func)\n",
    "    except ValueError as e:\n",
    "        # 如果获取签名失败，则抛出异常并显示具体的错误信息\n",
    "        raise ValueError(\n",
    "            f\"无法获取函数 {func.__name__} 的签名: {str(e)}\"\n",
    "        )\n",
    "\n",
    "    # 用于存储参数信息的字典\n",
    "    parameters = {}\n",
    "    for param in signature.parameters.values():\n",
    "        # 尝试获取参数的类型，如果无法找到对应的类型则默认设置为 \"string\"\n",
    "        try:\n",
    "            param_type = type_map.get(param.annotation, \"string\")\n",
    "        except KeyError as e:\n",
    "            # 如果参数类型不在 type_map 中，抛出异常并显示具体错误信息\n",
    "            raise KeyError(\n",
    "                f\"未知的类型注解 {param.annotation}，参数名为 {param.name}: {str(e)}\"\n",
    "            )\n",
    "        # 将参数名及其类型信息添加到参数字典中\n",
    "        parameters[param.name] = {\"type\": param_type}\n",
    "\n",
    "    # 获取函数中所有必需的参数（即没有默认值的参数）\n",
    "    required = [\n",
    "        param.name\n",
    "        for param in signature.parameters.values()\n",
    "        if param.default == inspect._empty\n",
    "    ]\n",
    "\n",
    "    # 返回包含函数描述信息的字典\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,  # 函数的名称\n",
    "            \"description\": func.__doc__ or \"\",  # 函数的文档字符串（如果不存在则为空字符串）\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": parameters,  # 函数参数的类型描述\n",
    "                \"required\": required,  # 必须参数的列表\n",
    "            },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9eaf0c",
   "metadata": {},
   "source": [
    "5. 构造 Agent 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "deaef500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: OpenAI, model: str = \"Qwen/Qwen2.5-32B-Instruct\", tools=None,\n",
    "                 verbose: bool = True):\n",
    "        if tools is None:\n",
    "            tools = []\n",
    "        self.client = client\n",
    "        self.tools = tools\n",
    "        self.model = model\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        ]\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def get_tool_schema(self) -> List[Dict[str, Any]]:\n",
    "        # 获取所有工具的 JSON 模式\n",
    "        return [function_to_json(tool) for tool in self.tools]\n",
    "\n",
    "    def handle_tool_call(self, tool_call):\n",
    "        # 处理工具调用\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = tool_call.function.arguments\n",
    "        function_id = tool_call.id\n",
    "\n",
    "        function_call_content = eval(f\"{function_name}(**{function_args})\")\n",
    "\n",
    "        return {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": function_call_content,\n",
    "            \"tool_call_id\": function_id,\n",
    "        }\n",
    "\n",
    "    def get_completion(self, prompt) -> str:\n",
    "\n",
    "        self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        # 获取模型的完成响应\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            tools=self.get_tool_schema(),\n",
    "            stream=False,\n",
    "        )\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "            # 处理工具调用\n",
    "            tool_list = []\n",
    "            for tool_call in response.choices[0].message.tool_calls:\n",
    "                # 处理工具调用并将结果添加到消息列表中\n",
    "                self.messages.append(self.handle_tool_call(tool_call))\n",
    "                tool_list.append([tool_call.function.name, tool_call.function.arguments])\n",
    "            if self.verbose:\n",
    "                print(\"调用工具：\", response.choices[0].message.content, tool_list)\n",
    "            # 再次获取模型的完成响应，这次包含工具调用的结果\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages,\n",
    "                tools=self.get_tool_schema(),\n",
    "                stream=False,\n",
    "            )\n",
    "\n",
    "        # 将模型的完成响应添加到消息列表中\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11fdd4",
   "metadata": {},
   "source": [
    "6. 启动Agent，可以开心聊天了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdc47fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "你是一个叫不要葱姜蒜的人工智能助手。你的输出应该与用户的语言保持一致。\n",
    "当用户的问题需要调用工具时，你可以从提供的工具列表中调用适当的工具函数。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7d4c75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 你好\n",
      "\u001b[92mAssistant: \u001b[0m 你好！有什么可以帮助你的吗？\n",
      "User: 9.12和9 .2哪个更大？\n",
      "调用工具：  [['compare', '{\"a\": 9.12, \"b\": 9.2}']]\n",
      "\u001b[92mAssistant: \u001b[0m 9.2 比 9.12 更大。\n",
      "User: 为什么？\n",
      "\u001b[92mAssistant: \u001b[0m 当我们比较两个数字的时候，我们会从左到右比较每一位的大小。对于 9.12 和 9.2，首先比较整数部分，它们都是 9，所以相等。然后比较小数部分，9.12 的小数部分是 12（可以认为是 1 和 2），而 9.2 的小数部分是 20（写成两位数时是 2 和 0）。因为 20 大于 12，所以 9.2 大于 9.12。\n",
      "\n",
      "实际上，9.2 可以写成 9.20，这更直观地显示出它的大小。因此，9.2 比 9.12 更大。\n",
      "User: strawberry中有几个r？\n",
      "调用工具：  [['count_letter_in_string', '{\"a\": \"strawberry\", \"b\": \"r\"}']]\n",
      "\u001b[92mAssistant: \u001b[0m 在单词 \"strawberry\" 中，字母 'r' 出现了 3 次。\n",
      "User: 现在是什么时候？\n",
      "调用工具：  [['get_current_datetime', '{}']]\n",
      "\u001b[92mAssistant: \u001b[0m 当前的时间是 2025 年 6 月 19 日 21 点 56 分 19 秒。请注意，这个时间是我的系统时间，可能与你的所在地时间有所不同。\n",
      "User: exit\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(\n",
    "    client=client,\n",
    "    model=\"Qwen/Qwen2.5-32B-Instruct\",\n",
    "    tools=[get_current_datetime, add, compare, count_letter_in_string],\n",
    ")\n",
    "\n",
    "while True:\n",
    "    # 使用彩色输出区分用户输入和AI回答\n",
    "    prompt = input(\"\\033[94mUser: \\033[0m\")  # 蓝色显示用户输入提示\n",
    "    if prompt == \"exit\":\n",
    "        break\n",
    "    response = agent.get_completion(prompt)\n",
    "    print(\"\\033[92mAssistant: \\033[0m\", response)  # 绿色显示AI助手回答"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
