# Task07 å¤§æ¨¡å‹åº”ç”¨

## 1 LLM çš„è¯„æµ‹

- LLM çš„è¯„æµ‹æ•°æ®é›†ï¼šé€šç”¨è¯„æµ‹é›†ï¼ˆMMLUï¼‰ã€å·¥å…·ä½¿ç”¨è¯„æµ‹é›†ï¼ˆBFCL V2ã€Nexusï¼‰ã€æ•°å­¦è¯„æµ‹é›†ï¼ˆGSM8Kã€MATHï¼‰ã€æ¨ç†è¯„æµ‹é›†ï¼ˆARC Challengeã€GPQAã€HellaSwagï¼‰ã€é•¿æ–‡æœ¬ç†è§£è¯„æµ‹é›†ï¼ˆInfiniteBench/En.MCã€NIH/Multi-needleï¼‰ã€å¤šè¯­è¨€è¯„æµ‹é›†ï¼ˆMGSMï¼‰
- ä¸»æµè¯„æµ‹æ¦œå•ï¼šOpen LLM Leaderboardã€Lmsys Chatbot Arena Leaderboardã€OpenCompassã€‚
- å‚ç±»è¯„æµ‹æ¦œå•ï¼šé‡‘èæ¦œï¼ˆåŸºäºCFBenchmarkè¯„æµ‹é›†ï¼‰ã€å®‰å…¨æ¦œï¼ˆåŸºäºFlamesè¯„æµ‹é›†ï¼‰ã€é€šè¯†æ¦œï¼ˆåŸºäºBotChatè¯„æµ‹é›†ï¼‰ã€æ³•å¾‹æ¦œï¼ˆåŸºäºLawBenchè¯„æµ‹é›†ï¼‰ã€åŒ»ç–—æ¦œï¼ˆåŸºäºMedBenchè¯„æµ‹é›†ï¼‰

## 2 RAG

### 2.1 RAGåŸç†

å°†â€œæ£€ç´¢â€ä¸â€œç”Ÿæˆâ€ç»“åˆï¼Œå½“ç”¨æˆ·æå‡ºæŸ¥è¯¢æ—¶ï¼Œç³»ç»Ÿé¦–å…ˆé€šè¿‡æ£€ç´¢æ¨¡å—æ‰¾åˆ°ä¸é—®é¢˜ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µï¼Œç„¶åå°†è¿™äº›ç‰‡æ®µä½œä¸ºé™„åŠ ä¿¡æ¯ä¼ é€’ç»™è¯­è¨€æ¨¡å‹ï¼Œæ¨¡å‹æ®æ­¤ç”Ÿæˆæ›´ä¸ºç²¾å‡†å’Œå¯é çš„å›ç­”ã€‚

### 2.2 æ­å»ºä¸€ä¸ª RAG æ¡†æ¶

- RAGåŸºæœ¬ç»“æ„ï¼šå‘é‡åŒ–æ¨¡å—ã€æ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†æ¨¡å—ã€æ•°æ®åº“ã€æ£€ç´¢æ¨¡å—ã€å¤§æ¨¡å‹æ¨¡å—ã€‚
- RAGä¸»è¦æµç¨‹ï¼šç´¢å¼•ã€æ£€ç´¢ã€ç”Ÿæˆã€‚

1. åŠ è½½pythonä¾èµ–åº“


```python
import json
import os
import re
from typing import List

import PyPDF2
import markdown
import numpy as np
import tiktoken
from bs4 import BeautifulSoup
from dotenv import load_dotenv, find_dotenv
from tqdm import tqdm
```

2. åŠ è½½ç¯å¢ƒå˜é‡ï¼Œç”¨äºåŠ è½½API_KEYã€‚


```python
loaded = load_dotenv(find_dotenv(), override=True)
```

3. å®ç°RAGå‘é‡åŒ–


```python
class BaseEmbeddings:
    """
    å‘é‡åŒ–åŸºç±»
    """

    def __init__(self, path: str, is_api: bool) -> None:
        self.path = path
        self.is_api = is_api

    def get_embedding(self, text: str, model: str=None) -> List[float]:
        raise NotImplementedError

    @classmethod
    def cosine_similarity(cls, vector1: List[float], vector2: List[float]) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        :param vector1: å‘é‡1
        :param vector2: å‘é‡2
        :return: ä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼åº¦
        """
        dot_product = np.dot(vector1, vector2)
        magnitude = np.linalg.norm(vector1) * np.linalg.norm(vector2)
        if not magnitude:
            return 0
        return dot_product / magnitude
```


```python
class SiliconFlowEmbedding(BaseEmbeddings):
    """
    åŸºäºç¡…åŸºæµåŠ¨çš„å‘é‡åŒ–ç±»
    """

    def __init__(self, path: str = '', is_api: bool = True) -> None:
        super().__init__(path, is_api)
        if self.is_api:
            from openai import OpenAI
            API_KEY = os.getenv("SiliconFlow_API_KEY")
            BASE_URL = os.getenv("SiliconFlow_BASE_URL")
            self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

    def get_embedding(self, text: str, model: str = "BAAI/bge-m3") -> List[float]:
        if self.is_api:
            text = text.replace("\n", " ")
            return self.client.embeddings.create(input=[text], model=model).data[0].embedding
        else:
            raise NotImplementedError
```

4. å®ç°æ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†


```python
class ReadFiles:
    """
    class to read files
    """
    enc = tiktoken.get_encoding("cl100k_base")

    def __init__(self, path: str) -> None:
        self._path = path
        self.file_list = self.get_files()

    def get_files(self):
        # argsï¼šdir_pathï¼Œç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
        file_list = []
        for filepath, dirnames, filenames in os.walk(self._path):
            # os.walk å‡½æ•°å°†é€’å½’éå†æŒ‡å®šæ–‡ä»¶å¤¹
            for filename in filenames:
                # é€šè¿‡åç¼€ååˆ¤æ–­æ–‡ä»¶ç±»å‹æ˜¯å¦æ»¡è¶³è¦æ±‚
                if filename.endswith(".md"):
                    # å¦‚æœæ»¡è¶³è¦æ±‚ï¼Œå°†å…¶ç»å¯¹è·¯å¾„åŠ å…¥åˆ°ç»“æœåˆ—è¡¨
                    file_list.append(os.path.join(filepath, filename))
                elif filename.endswith(".txt"):
                    file_list.append(os.path.join(filepath, filename))
                elif filename.endswith(".pdf"):
                    file_list.append(os.path.join(filepath, filename))
        return file_list

    def get_content(self, max_token_len: int = 600, cover_content: int = 150):
        docs = []
        # è¯»å–æ–‡ä»¶å†…å®¹
        for file in self.file_list:
            content = self.read_file_content(file)
            chunk_content = self.get_chunk(
                content, max_token_len=max_token_len, cover_content=cover_content)
            docs.extend(chunk_content)
        return docs

    @classmethod
    def read_file_content(cls, file_path: str):
        """
        æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è¯»å–æ–¹æ³•
        """
        if file_path.endswith('.pdf'):
            return cls.read_pdf(file_path)
        elif file_path.endswith('.md'):
            return cls.read_markdown(file_path)
        elif file_path.endswith('.txt'):
            return cls.read_text(file_path)
        else:
            raise ValueError("Unsupported file type")

    @classmethod
    def get_chunk(cls, text: str, max_token_len: int = 600, cover_content: int = 150):
        chunk_text = []

        curr_len = 0
        curr_chunk = ''

        token_len = max_token_len - cover_content
        lines = text.splitlines()  # å‡è®¾ä»¥æ¢è¡Œç¬¦åˆ†å‰²æ–‡æœ¬ä¸ºè¡Œ

        for line in lines:
            line = line.replace(' ', '')
            line_len = len(cls.enc.encode(line))
            if line_len > max_token_len:
                # å¦‚æœå•è¡Œé•¿åº¦å°±è¶…è¿‡é™åˆ¶ï¼Œåˆ™å°†å…¶åˆ†å‰²æˆå¤šä¸ªå—
                num_chunks = (line_len + token_len - 1) // token_len
                for i in range(num_chunks):
                    start = i * token_len
                    end = start + token_len
                    # é¿å…è·¨å•è¯åˆ†å‰²
                    while not line[start:end].rstrip().isspace():
                        start += 1
                        end += 1
                        if start >= line_len:
                            break
                    curr_chunk = curr_chunk[-cover_content:] + line[start:end]
                    chunk_text.append(curr_chunk)
                # å¤„ç†æœ€åä¸€ä¸ªå—
                start = (num_chunks - 1) * token_len
                curr_chunk = curr_chunk[-cover_content:] + line[start:end]
                chunk_text.append(curr_chunk)

            if curr_len + line_len <= token_len:
                curr_chunk += line
                curr_chunk += '\n'
                curr_len += line_len
                curr_len += 1
            else:
                chunk_text.append(curr_chunk)
                curr_chunk = curr_chunk[-cover_content:] + line
                curr_len = line_len + cover_content

        if curr_chunk:
            chunk_text.append(curr_chunk)

        return chunk_text

    @classmethod
    def read_pdf(cls, file_path: str):
        # è¯»å–PDFæ–‡ä»¶
        with open(file_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page_num in range(len(reader.pages)):
                text += reader.pages[page_num].extract_text()
            return text

    @classmethod
    def read_markdown(cls, file_path: str):
        # è¯»å–Markdownæ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as file:
            md_text = file.read()
            html_text = markdown.markdown(md_text)
            # ä½¿ç”¨BeautifulSoupä»HTMLä¸­æå–çº¯æ–‡æœ¬
            soup = BeautifulSoup(html_text, 'html.parser')
            plain_text = soup.get_text()
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤ç½‘å€é“¾æ¥
            text = re.sub(r'http\S+', '', plain_text)
            return text

    @classmethod
    def read_text(cls, file_path: str):
        # è¯»å–æ–‡æœ¬æ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()
```

5. å®ç°æ•°æ®åº“ä¸å‘é‡æ£€ç´¢


```python
class VectorStore:
    def __init__(self, document=None) -> None:
        self.vectors = None
        if document is None:
            document = ['']
        self.document = document

    def get_vector(self, EmbeddingModel: BaseEmbeddings) -> List[List[float]]:
        self.vectors = []
        for doc in tqdm(self.document, desc="Calculating embeddings"):
            self.vectors.append(EmbeddingModel.get_embedding(doc))
        return self.vectors

    def persist(self, path: str = '../../storage'):
        if not os.path.exists(path):
            os.makedirs(path)
        with open(f"{path}/doecment.json", 'w', encoding='utf-8') as f:
            json.dump(self.document, f, ensure_ascii=False)
        if self.vectors:
            with open(f"{path}/vectors.json", 'w', encoding='utf-8') as f:
                json.dump(self.vectors, f)

    def load_vector(self, path: str = 'storage'):
        with open(f"{path}/vectors.json", 'r', encoding='utf-8') as f:
            self.vectors = json.load(f)
        with open(f"{path}/doecment.json", 'r', encoding='utf-8') as f:
            self.document = json.load(f)

    def get_similarity(self, vector1: List[float], vector2: List[float]) -> float:
        return BaseEmbeddings.cosine_similarity(vector1, vector2)

    def query(self, query: str, EmbeddingModel: BaseEmbeddings, k: int = 1) -> List[str]:
        query_vector = EmbeddingModel.get_embedding(query)
        result = np.array([self.get_similarity(query_vector, vector)
                           for vector in self.vectors])
        return np.array(self.document)[result.argsort()[-k:][::-1]].tolist()
```

6. å®ç°å¤§æ¨¡å‹æ¨¡å—


```python
class BaseModel:
    def __init__(self, path: str = '') -> None:
        self.path = path

    def chat(self, prompt: str, history: List[dict], content: str) -> str:
        pass

    def load_model(self):
        pass
```


```python
class SiliconFlowChat(BaseModel):
    def __init__(self, path: str = '', model: str = "Qwen/Qwen3-8B") -> None:
        super().__init__(path)
        self.model = model

    def chat(self, prompt: str, history: List[dict], content: str) -> str:
        from openai import OpenAI
        API_KEY = os.getenv("SiliconFlow_API_KEY")
        BASE_URL = os.getenv("SiliconFlow_BASE_URL")
        client = OpenAI(api_key=API_KEY, base_url=BASE_URL, max_retries=3)
        history.append({'role': 'user',
                        'content': PROMPT_TEMPLATE['RAG_PROMPT_TEMPLATE'].format(question=prompt, context=content)})
        response = client.chat.completions.create(
            model=self.model,
            messages=history,
            max_tokens=1024,
            temperature=0.1
        )
        return response.choices[0].message.content
```

7. ç”¨ä¸€ä¸ªå­—å…¸æ¥ä¿å­˜æ‰€æœ‰çš„promptï¼Œæ–¹ä¾¿ç»´æŠ¤


```python
PROMPT_TEMPLATE = dict(
    RAG_PROMPT_TEMPLATE="""ä½¿ç”¨ä»¥ä¸Šä¸‹æ–‡æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ã€‚æ€»æ˜¯ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚
        é—®é¢˜: {question}
        å¯å‚è€ƒçš„ä¸Šä¸‹æ–‡ï¼š
        Â·Â·Â·
        {context}
        Â·Â·Â·
        å¦‚æœç»™å®šçš„ä¸Šä¸‹æ–‡æ— æ³•è®©ä½ åšå‡ºå›ç­”ï¼Œè¯·å›ç­”æ•°æ®åº“ä¸­æ²¡æœ‰è¿™ä¸ªå†…å®¹ï¼Œä½ ä¸çŸ¥é“ã€‚
        æœ‰ç”¨çš„å›ç­”:"""
)
```

8. å¼€å§‹åŸºäºçŸ¥è¯†åº“èŠå¤©äº†ï¼Œæˆ‘ä»¬ä¸Šä¼ äº†ä¸€ä¸ªGitä»‹ç»çš„æ–‡æ¡£ï¼Œç„¶åå¯ä»¥é’ˆå¯¹è¿™ä¸ªæ–‡æ¡£æ¥æé—®


```python
# æ²¡æœ‰ä¿å­˜æ•°æ®åº“
rf = ReadFiles('../data')
docs = rf.get_content(max_token_len=600, cover_content=150)  # è·å–dataç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å†…å®¹å¹¶åˆ†å‰²
vector = VectorStore(docs)
embedding = SiliconFlowEmbedding()  # åˆ›å»ºEmbeddingModel
vector.get_vector(EmbeddingModel=embedding)
# å°†å‘é‡å’Œæ–‡æ¡£å†…å®¹ä¿å­˜åˆ°storageç›®å½•ï¼Œä¸‹æ¬¡å†ç”¨å¯ä»¥ç›´æ¥åŠ è½½æœ¬åœ°æ•°æ®åº“
vector.persist(path='../storage')

question = 'gitçš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ'

rag_content = vector.query(question, embedding, k=1)[0]
chat = SiliconFlowChat(model="deepseek-ai/DeepSeek-V3")
print(chat.chat(question, [], rag_content))
```

    Calculating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 10.59it/s]
    

    Gitçš„åŸç†ä¸»è¦åŸºäºä»¥ä¸‹æ ¸å¿ƒæ¦‚å¿µå’Œæœºåˆ¶ï¼š
    
    1. ä¸‰å¤§åŒºåŸŸç»“æ„ï¼š
    - å·¥ä½œåŒºï¼šç›´æ¥ç¼–è¾‘æ–‡ä»¶çš„ç‰©ç†ç›®å½•
    - æš‚å­˜åŒºï¼ˆIndexï¼‰ï¼šä¸´æ—¶å­˜å‚¨å˜æ›´çš„å¿«ç…§åŒº
    - ç‰ˆæœ¬åº“ï¼šæ°¸ä¹…å­˜å‚¨é¡¹ç›®å†å²çš„æ•°æ®åº“
    
    2. ä¸‰å¤§çŠ¶æ€è½¬æ¢ï¼š
    - å·²ä¿®æ”¹ â†’ git add â†’ å·²æš‚å­˜
    - å·²æš‚å­˜ â†’ git commit â†’ å·²æäº¤
    - å·²æäº¤ â†’ git checkout â†’ å·¥ä½œåŒº
    
    3. åˆ†å¸ƒå¼æ¶æ„ï¼š
    æ¯ä¸ªå¼€å‘è€…æœ¬åœ°éƒ½æœ‰å®Œæ•´çš„ç‰ˆæœ¬åº“ï¼ŒåŒ…å«å…¨éƒ¨å†å²è®°å½•ï¼Œé€šè¿‡æ¨é€(push)/æ‹‰å–(pull)å®ç°åä½œã€‚
    
    4. æ•°æ®å­˜å‚¨åŸç†ï¼š
    ä½¿ç”¨SHA-1å“ˆå¸Œç®—æ³•ç”Ÿæˆå”¯ä¸€å¯¹è±¡IDï¼Œä»¥é”®å€¼å¯¹å½¢å¼å­˜å‚¨ï¼š
    - blobå¯¹è±¡ï¼šå­˜å‚¨æ–‡ä»¶å†…å®¹
    - treeå¯¹è±¡ï¼šè®°å½•ç›®å½•ç»“æ„
    - commitå¯¹è±¡ï¼šåŒ…å«æäº¤å…ƒæ•°æ®å’ŒæŒ‡å‘treeçš„æŒ‡é’ˆ
    
    5. ç‰ˆæœ¬æ§åˆ¶æœºåˆ¶ï¼š
    é€šè¿‡æœ‰å‘æ— ç¯å›¾(DAG)ç®¡ç†æäº¤å†å²ï¼Œåˆ†æ”¯åªæ˜¯æŒ‡å‘ç‰¹å®šæäº¤çš„å¯å˜æŒ‡é’ˆã€‚
    
    è¿™ç§è®¾è®¡ä½¿å¾—Gitå…·æœ‰å¼ºå¤§çš„åˆ†æ”¯ç®¡ç†èƒ½åŠ›ã€é«˜æ•ˆçš„æœ¬åœ°æ“ä½œå’Œå®Œæ•´çš„å†å²è¿½æº¯åŠŸèƒ½ã€‚
    

## 3 Agent

### 3.1 LLM Agent

- LLM Agentç®€ä»‹ï¼šå¤§æ¨¡å‹Agentæ˜¯ä¸€ä¸ªä»¥LLMä¸ºæ ¸å¿ƒâ€œå¤§è„‘â€ï¼Œå¹¶èµ‹äºˆå…¶è‡ªä¸»è§„åˆ’ã€è®°å¿†å’Œä½¿ç”¨å·¥å…·èƒ½åŠ›çš„ç³»ç»Ÿã€‚
- LLM Agent çš„ç±»å‹ï¼š
    1. ä»»åŠ¡å¯¼å‘å‹Agentï¼šä¸“æ³¨äºå®Œæˆç‰¹å®šé¢†åŸŸçš„ã€å®šä¹‰æ˜ç¡®çš„ä»»åŠ¡ï¼Œä½¿ç”¨é¢„è®¾çš„æµç¨‹å’Œå¯è°ƒç”¨çš„ç‰¹å®šå·¥å…·é›†ã€‚
    2. è§„åˆ’ä¸æ¨ç†å‹Agentï¼šå¼ºè°ƒè‡ªä¸»åˆ†è§£å¤æ‚ä»»åŠ¡ã€åˆ¶å®šå¤šæ­¥è®¡åˆ’ï¼Œé‡‡ç”¨ç‰¹å®šçš„æ€ç»´æ¡†æ¶ã€‚
    3. å¤šAgentç³»ç»Ÿï¼šç”±å¤šä¸ªå…·æœ‰ä¸åŒè§’è‰²æˆ–èƒ½åŠ›çš„AgentååŒå·¥ä½œï¼Œå…±åŒå®Œæˆä¸€ä¸ªæ›´å®å¤§çš„ç›®æ ‡ã€‚
    4. æ¢ç´¢ä¸å­¦ä¹ å‹Agentï¼š ä¸ä»…æ‰§è¡Œä»»åŠ¡ï¼Œè¿˜èƒ½åœ¨ä¸ç¯å¢ƒçš„äº¤äº’ä¸­ä¸»åŠ¨å­¦ä¹ æ–°çŸ¥è¯†ã€æ–°æŠ€èƒ½æˆ–ä¼˜åŒ–è‡ªèº«ç­–ç•¥ï¼Œå¯èƒ½åŒ…å«æ›´å¤æ‚çš„è®°å¿†å’Œåæ€æœºåˆ¶ã€‚

### 3.2 æ­å»ºä¸€ä¸ªAgent

1. åŠ è½½pythonä¾èµ–åº“


```python
import inspect
import os
from datetime import datetime
from typing import List, Dict, Any

from dotenv import load_dotenv, find_dotenv
from openai import OpenAI
```

2. åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œæ¨¡å‹


```python
loaded = load_dotenv(find_dotenv(), override=True)

API_KEY = os.getenv("SiliconFlow_API_KEY")
BASE_URL = os.getenv("SiliconFlow_BASE_URL")
client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
```

3. å®šä¹‰å·¥å…·å‡½æ•°


```python
def get_current_datetime() -> str:
    """
    è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´ã€‚
    :return: å½“å‰æ—¥æœŸå’Œæ—¶é—´çš„å­—ç¬¦ä¸²è¡¨ç¤ºã€‚
    """
    current_datetime = datetime.now()
    formatted_datetime = current_datetime.strftime("%Y-%m-%d %H:%M:%S")
    return formatted_datetime


def add(a: float, b: float):
    """
    è®¡ç®—ä¸¤ä¸ªæµ®ç‚¹æ•°çš„å’Œã€‚
    :param a: ç¬¬ä¸€ä¸ªæµ®ç‚¹æ•°ã€‚
    :param b: ç¬¬äºŒä¸ªæµ®ç‚¹æ•°ã€‚
    :return: ä¸¤ä¸ªæµ®ç‚¹æ•°çš„å’Œã€‚
    """
    return str(a + b)


def mul(a: float, b: float):
    """
    è®¡ç®—ä¸¤ä¸ªæµ®ç‚¹æ•°çš„ç§¯ã€‚
    :param a: ç¬¬ä¸€ä¸ªæµ®ç‚¹æ•°ã€‚
    :param b: ç¬¬äºŒä¸ªæµ®ç‚¹æ•°ã€‚
    :return: ä¸¤ä¸ªæµ®ç‚¹æ•°çš„ç§¯ã€‚
    """
    return str(a * b)


def compare(a: float, b: float):
    """
    æ¯”è¾ƒä¸¤ä¸ªæµ®ç‚¹æ•°çš„å¤§å°ã€‚
    :param a: ç¬¬ä¸€ä¸ªæµ®ç‚¹æ•°ã€‚
    :param b: ç¬¬äºŒä¸ªæµ®ç‚¹æ•°ã€‚
    :return: æ¯”è¾ƒç»“æœçš„å­—ç¬¦ä¸²è¡¨ç¤ºã€‚
    """
    if a > b:
        return f'{a} is greater than {b}'
    elif a < b:
        return f'{b} is greater than {a}'
    else:
        return f'{a} is equal to {b}'


def count_letter_in_string(a: str, b: str):
    """
    ç»Ÿè®¡å­—ç¬¦ä¸²ä¸­æŸä¸ªå­—æ¯çš„å‡ºç°æ¬¡æ•°ã€‚
    :param a: è¦æœç´¢çš„å­—ç¬¦ä¸²ã€‚
    :param b: è¦ç»Ÿè®¡çš„å­—æ¯ã€‚
    :return: å­—æ¯åœ¨å­—ç¬¦ä¸²ä¸­å‡ºç°çš„æ¬¡æ•°ã€‚
    """
    string = a.lower()
    letter = b.lower()

    count = string.count(letter)
    return f"The letter '{letter}' appears {count} times in the string."
```

4. å°†å·¥å…·ç±»è½¬æ¢æˆç‰¹å®šçš„ JSON Schema æ ¼å¼


```python
def function_to_json(func) -> dict:
    # å®šä¹‰ Python ç±»å‹åˆ° JSON æ•°æ®ç±»å‹çš„æ˜ å°„
    type_map = {
        str: "string",  # å­—ç¬¦ä¸²ç±»å‹æ˜ å°„ä¸º JSON çš„ "string"
        int: "integer",  # æ•´å‹ç±»å‹æ˜ å°„ä¸º JSON çš„ "integer"
        float: "number",  # æµ®ç‚¹å‹æ˜ å°„ä¸º JSON çš„ "number"
        bool: "boolean",  # å¸ƒå°”å‹æ˜ å°„ä¸º JSON çš„ "boolean"
        list: "array",  # åˆ—è¡¨ç±»å‹æ˜ å°„ä¸º JSON çš„ "array"
        dict: "object",  # å­—å…¸ç±»å‹æ˜ å°„ä¸º JSON çš„ "object"
        type(None): "null",  # None ç±»å‹æ˜ å°„ä¸º JSON çš„ "null"
    }

    # è·å–å‡½æ•°çš„ç­¾åä¿¡æ¯
    try:
        signature = inspect.signature(func)
    except ValueError as e:
        # å¦‚æœè·å–ç­¾åå¤±è´¥ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸å¹¶æ˜¾ç¤ºå…·ä½“çš„é”™è¯¯ä¿¡æ¯
        raise ValueError(
            f"æ— æ³•è·å–å‡½æ•° {func.__name__} çš„ç­¾å: {str(e)}"
        )

    # ç”¨äºå­˜å‚¨å‚æ•°ä¿¡æ¯çš„å­—å…¸
    parameters = {}
    for param in signature.parameters.values():
        # å°è¯•è·å–å‚æ•°çš„ç±»å‹ï¼Œå¦‚æœæ— æ³•æ‰¾åˆ°å¯¹åº”çš„ç±»å‹åˆ™é»˜è®¤è®¾ç½®ä¸º "string"
        try:
            param_type = type_map.get(param.annotation, "string")
        except KeyError as e:
            # å¦‚æœå‚æ•°ç±»å‹ä¸åœ¨ type_map ä¸­ï¼ŒæŠ›å‡ºå¼‚å¸¸å¹¶æ˜¾ç¤ºå…·ä½“é”™è¯¯ä¿¡æ¯
            raise KeyError(
                f"æœªçŸ¥çš„ç±»å‹æ³¨è§£ {param.annotation}ï¼Œå‚æ•°åä¸º {param.name}: {str(e)}"
            )
        # å°†å‚æ•°ååŠå…¶ç±»å‹ä¿¡æ¯æ·»åŠ åˆ°å‚æ•°å­—å…¸ä¸­
        parameters[param.name] = {"type": param_type}

    # è·å–å‡½æ•°ä¸­æ‰€æœ‰å¿…éœ€çš„å‚æ•°ï¼ˆå³æ²¡æœ‰é»˜è®¤å€¼çš„å‚æ•°ï¼‰
    required = [
        param.name
        for param in signature.parameters.values()
        if param.default == inspect._empty
    ]

    # è¿”å›åŒ…å«å‡½æ•°æè¿°ä¿¡æ¯çš„å­—å…¸
    return {
        "type": "function",
        "function": {
            "name": func.__name__,  # å‡½æ•°çš„åç§°
            "description": func.__doc__ or "",  # å‡½æ•°çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
            "parameters": {
                "type": "object",
                "properties": parameters,  # å‡½æ•°å‚æ•°çš„ç±»å‹æè¿°
                "required": required,  # å¿…é¡»å‚æ•°çš„åˆ—è¡¨
            },
        },
    }
```

5. æ„é€  Agent ç±»


```python
class Agent:
    def __init__(self, client: OpenAI, model: str = "Qwen/Qwen2.5-32B-Instruct", tools=None,
                 verbose: bool = True):
        if tools is None:
            tools = []
        self.client = client
        self.tools = tools
        self.model = model
        self.messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
        ]
        self.verbose = verbose

    def get_tool_schema(self) -> List[Dict[str, Any]]:
        # è·å–æ‰€æœ‰å·¥å…·çš„ JSON æ¨¡å¼
        return [function_to_json(tool) for tool in self.tools]

    def handle_tool_call(self, tool_call):
        # å¤„ç†å·¥å…·è°ƒç”¨
        function_name = tool_call.function.name
        function_args = tool_call.function.arguments
        function_id = tool_call.id

        function_call_content = eval(f"{function_name}(**{function_args})")

        return {
            "role": "tool",
            "content": function_call_content,
            "tool_call_id": function_id,
        }

    def get_completion(self, prompt) -> str:

        self.messages.append({"role": "user", "content": prompt})

        # è·å–æ¨¡å‹çš„å®Œæˆå“åº”
        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.messages,
            tools=self.get_tool_schema(),
            stream=False,
        )
        if response.choices[0].message.tool_calls:
            self.messages.append({"role": "assistant", "content": response.choices[0].message.content})
            # å¤„ç†å·¥å…·è°ƒç”¨
            tool_list = []
            for tool_call in response.choices[0].message.tool_calls:
                # å¤„ç†å·¥å…·è°ƒç”¨å¹¶å°†ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
                self.messages.append(self.handle_tool_call(tool_call))
                tool_list.append([tool_call.function.name, tool_call.function.arguments])
            if self.verbose:
                print("è°ƒç”¨å·¥å…·ï¼š", response.choices[0].message.content, tool_list)
            # å†æ¬¡è·å–æ¨¡å‹çš„å®Œæˆå“åº”ï¼Œè¿™æ¬¡åŒ…å«å·¥å…·è°ƒç”¨çš„ç»“æœ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=self.messages,
                tools=self.get_tool_schema(),
                stream=False,
            )

        # å°†æ¨¡å‹çš„å®Œæˆå“åº”æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
        self.messages.append({"role": "assistant", "content": response.choices[0].message.content})
        return response.choices[0].message.content
```

6. å¯åŠ¨Agentï¼Œå¯ä»¥å¼€å¿ƒèŠå¤©äº†ï¼


```python
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªå«ä¸è¦è‘±å§œè’œçš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ çš„è¾“å‡ºåº”è¯¥ä¸ç”¨æˆ·çš„è¯­è¨€ä¿æŒä¸€è‡´ã€‚
å½“ç”¨æˆ·çš„é—®é¢˜éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œä½ å¯ä»¥ä»æä¾›çš„å·¥å…·åˆ—è¡¨ä¸­è°ƒç”¨é€‚å½“çš„å·¥å…·å‡½æ•°ã€‚
"""
```


```python
agent = Agent(
    client=client,
    model="Qwen/Qwen2.5-32B-Instruct",
    tools=[get_current_datetime, add, compare, count_letter_in_string],
)

while True:
    # ä½¿ç”¨å½©è‰²è¾“å‡ºåŒºåˆ†ç”¨æˆ·è¾“å…¥å’ŒAIå›ç­”
    prompt = input("\033[94mUser: \033[0m")  # è“è‰²æ˜¾ç¤ºç”¨æˆ·è¾“å…¥æç¤º
    if prompt == "exit":
        break
    response = agent.get_completion(prompt)
    print("\033[92mAssistant: \033[0m", response)  # ç»¿è‰²æ˜¾ç¤ºAIåŠ©æ‰‹å›ç­”
```

    User: ä½ å¥½
    [92mAssistant: [0m ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
    User: 9.12å’Œ9 .2å“ªä¸ªæ›´å¤§ï¼Ÿ
    è°ƒç”¨å·¥å…·ï¼š  [['compare', '{"a": 9.12, "b": 9.2}']]
    [92mAssistant: [0m 9.2 æ¯” 9.12 æ›´å¤§ã€‚
    User: ä¸ºä»€ä¹ˆï¼Ÿ
    [92mAssistant: [0m å½“æˆ‘ä»¬æ¯”è¾ƒä¸¤ä¸ªæ•°å­—çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¼šä»å·¦åˆ°å³æ¯”è¾ƒæ¯ä¸€ä½çš„å¤§å°ã€‚å¯¹äº 9.12 å’Œ 9.2ï¼Œé¦–å…ˆæ¯”è¾ƒæ•´æ•°éƒ¨åˆ†ï¼Œå®ƒä»¬éƒ½æ˜¯ 9ï¼Œæ‰€ä»¥ç›¸ç­‰ã€‚ç„¶åæ¯”è¾ƒå°æ•°éƒ¨åˆ†ï¼Œ9.12 çš„å°æ•°éƒ¨åˆ†æ˜¯ 12ï¼ˆå¯ä»¥è®¤ä¸ºæ˜¯ 1 å’Œ 2ï¼‰ï¼Œè€Œ 9.2 çš„å°æ•°éƒ¨åˆ†æ˜¯ 20ï¼ˆå†™æˆä¸¤ä½æ•°æ—¶æ˜¯ 2 å’Œ 0ï¼‰ã€‚å› ä¸º 20 å¤§äº 12ï¼Œæ‰€ä»¥ 9.2 å¤§äº 9.12ã€‚
    
    å®é™…ä¸Šï¼Œ9.2 å¯ä»¥å†™æˆ 9.20ï¼Œè¿™æ›´ç›´è§‚åœ°æ˜¾ç¤ºå‡ºå®ƒçš„å¤§å°ã€‚å› æ­¤ï¼Œ9.2 æ¯” 9.12 æ›´å¤§ã€‚
    User: strawberryä¸­æœ‰å‡ ä¸ªrï¼Ÿ
    è°ƒç”¨å·¥å…·ï¼š  [['count_letter_in_string', '{"a": "strawberry", "b": "r"}']]
    [92mAssistant: [0m åœ¨å•è¯ "strawberry" ä¸­ï¼Œå­—æ¯ 'r' å‡ºç°äº† 3 æ¬¡ã€‚
    User: ç°åœ¨æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ
    è°ƒç”¨å·¥å…·ï¼š  [['get_current_datetime', '{}']]
    [92mAssistant: [0m å½“å‰çš„æ—¶é—´æ˜¯ 2025 å¹´ 6 æœˆ 19 æ—¥ 21 ç‚¹ 56 åˆ† 19 ç§’ã€‚è¯·æ³¨æ„ï¼Œè¿™ä¸ªæ—¶é—´æ˜¯æˆ‘çš„ç³»ç»Ÿæ—¶é—´ï¼Œå¯èƒ½ä¸ä½ çš„æ‰€åœ¨åœ°æ—¶é—´æœ‰æ‰€ä¸åŒã€‚
    User: exit
    
